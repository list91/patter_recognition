#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏ –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
—Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ confidence.
"""

import yaml
import sys
from pathlib import Path
from ultralytics import YOLO
from collections import Counter
import cv2
import numpy as np
import shutil
import random

def load_config(config_path="train_config.yaml"):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ YAML —Ñ–∞–π–ª–∞."""
    if not Path(config_path).exists():
        print(f"‚ö†Ô∏è  –ö–æ–Ω—Ñ–∏–≥ {config_path} –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        return {}

    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config

def convert_to_grayscale_dataset(source_dir, target_dir):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ grayscale –∏ –∫–æ–ø–∏—Ä—É–µ—Ç –≤ —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é."""
    source_path = Path(source_dir)
    target_path = Path(target_dir)

    # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    target_path.mkdir(parents=True, exist_ok=True)

    print(f"üé® –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —á–µ—Ä–Ω–æ-–±–µ–ª—ã–µ...")
    print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {source_path}")
    print(f"   –¶–µ–ª—å: {target_path}")

    converted_count = 0
    for img_file in source_path.glob("*.jpg"):
        # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = cv2.imread(str(img_file))
        if img is None:
            continue

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ 3-–∫–∞–Ω–∞–ª—å–Ω–æ–µ (–¥—É–±–ª–∏—Ä—É–µ–º –∫–∞–Ω–∞–ª)
        # –≠—Ç–æ –Ω—É–∂–Ω–æ –ø–æ—Ç–æ–º—É —á—Ç–æ YOLO –æ–∂–∏–¥–∞–µ—Ç 3-–∫–∞–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        gray_3ch = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        target_file = target_path / img_file.name
        cv2.imwrite(str(target_file), gray_3ch)
        converted_count += 1

    print(f"   ‚úì –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {converted_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n")
    return target_path

def prepare_grayscale_dataset():
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —á–µ—Ä–Ω–æ-–±–µ–ª—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."""
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º train –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    train_source = Path("data/images/train")
    train_target = Path("data/images/train_grayscale")
    convert_to_grayscale_dataset(train_source, train_target)

    # –ö–æ–ø–∏—Ä—É–µ–º labels
    labels_source = Path("data/labels/train")
    labels_target = Path("data/labels/train_grayscale")

    labels_target.mkdir(parents=True, exist_ok=True)

    for label_file in labels_source.glob("*.txt"):
        shutil.copy2(label_file, labels_target / label_file.name)

    print(f"   ‚úì –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã –º–µ—Ç–∫–∏ –≤ {labels_target}\n")

    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π data.yaml –¥–ª—è grayscale
    data_yaml_content = """path: ./data
train: images/train_grayscale
val: images/train_grayscale
nc: 1
names: ['switch']
"""

    with open("data_grayscale.yaml", 'w') as f:
        f.write(data_yaml_content)

    print(f"   ‚úì –°–æ–∑–¥–∞–Ω data_grayscale.yaml\n")

    return "data_grayscale.yaml"

def train_model(config):
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
    print("=" * 70)
    print("üöÄ –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("=" * 70)
    print(f"\nüìã –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {config.get('experiment_name', 'default')}")
    print(f"üì¶ –ú–æ–¥–µ–ª—å: {config.get('model', 'yolo11n.pt')}")
    print(f"‚è±Ô∏è  –≠–ø–æ—Ö–∏: {config.get('epochs', 150)}")
    print(f"üìê –†–∞–∑–º–µ—Ä: {config.get('imgsz', 1280)}")
    print(f"üéØ Confidence threshold: {config.get('conf_threshold', 0.1)}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–∏–º grayscale
    use_grayscale = config.get('grayscale', False)
    print(f"üé® –†–µ–∂–∏–º: {'–ß–µ—Ä–Ω–æ-–±–µ–ª—ã–π (grayscale)' if use_grayscale else '–¶–≤–µ—Ç–Ω–æ–π (RGB)'}\n")

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    if use_grayscale:
        data_yaml = prepare_grayscale_dataset()
    else:
        data_yaml = "data.yaml"

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = YOLO(config.get('model', 'yolo11n.pt'))

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
    print("‚è≥ –û–±—É—á–µ–Ω–∏–µ –Ω–∞—á–∞–ª–æ—Å—å...\n")
    print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –¥–µ—Ñ–æ–ª—Ç—ã YOLO (–≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ù–ï –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è)\n")

    results = model.train(
        data=data_yaml,

        # –¢–æ–ª—å–∫–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–ù–ï –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è)
        device="cpu",
        workers=2,
        project="runs/detect",
        name="quick_train",
        exist_ok=True,  # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º
        verbose=False,  # –ú–µ–Ω—å—à–µ –≤—ã–≤–æ–¥–∞
        plots=True,
    )

    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
    best_model_path = Path(model.trainer.save_dir) / "weights" / "best.pt"

    print("\n" + "=" * 70)
    print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 70)
    print(f"üìÅ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {best_model_path}\n")

    return best_model_path

def test_on_train_image(model_path, conf_threshold=0.1, use_grayscale=False):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."""
    print("=" * 70)
    print("üîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –¢–†–ï–ù–ò–†–û–í–û–ß–ù–û–ú –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ò")
    print("=" * 70)

    train_image = Path("data/images/train/train_00.jpg")

    if not train_image.exists():
        print(f"‚ùå –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {train_image}")
        return

    print(f"\nüì∑ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {train_image}")
    print(f"üéØ –ü–æ—Ä–æ–≥ confidence: {conf_threshold}")
    print(f"üé® –†–µ–∂–∏–º: {'–ß–µ—Ä–Ω–æ-–±–µ–ª—ã–π (grayscale)' if use_grayscale else '–¶–≤–µ—Ç–Ω–æ–π (RGB)'}\n")

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    if use_grayscale:
        # –ß–∏—Ç–∞–µ–º –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale
        img = cv2.imread(str(train_image))
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        gray_3ch = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ
        temp_image = Path("data/images/train/train_00_grayscale_temp.jpg")
        cv2.imwrite(str(temp_image), gray_3ch)
        test_image = temp_image
    else:
        test_image = train_image

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = YOLO(model_path)

    # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    results = model.predict(
        source=str(test_image),
        imgsz=1280,
        conf=conf_threshold,
        iou=0.45,
        save=False,
        verbose=False,
    )

    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    result = results[0]
    boxes = result.boxes

    if len(boxes) == 0:
        print("‚ùå –û–±—ä–µ–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
        print("   - –°–Ω–∏–∑–∏—Ç—å conf_threshold")
        print("   - –£–≤–µ–ª–∏—á–∏—Ç—å epochs")
        print("   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à—É—é –º–æ–¥–µ–ª—å\n")

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        if use_grayscale and temp_image.exists():
            temp_image.unlink()
        return

    confidences = boxes.conf.cpu().numpy()

    # –ß–∏—Ç–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
    if use_grayscale:
        img = cv2.imread(str(test_image))
    else:
        img = cv2.imread(str(train_image))

    # –°–æ–∑–¥–∞–µ–º PREDICTION –∫–æ–ø–∏—é –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
    prediction_img = img.copy()

    # –°–æ–∑–¥–∞–µ–º GROUND TRUTH –∫–æ–ø–∏—é –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
    gt_img = img.copy()

    # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ —Å–æ—Ç—ã—Ö –∏ —Å—á–∏—Ç–∞–µ–º
    rounded_confs = [round(float(c), 2) for c in confidences]
    conf_counts = Counter(rounded_confs)

    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã boxes
    boxes_xyxy = boxes.xyxy.cpu().numpy()

    # ===== –õ–ï–í–ê–Ø –ß–ê–°–¢–¨: PREDICTIONS =====
    for i, (box, conf) in enumerate(zip(boxes_xyxy, confidences)):
        conf_val = float(conf)
        x1, y1, x2, y2 = map(int, box)

        # –¶–≤–µ—Ç –ø–æ —É—Ä–æ–≤–Ω—é confidence
        if conf_val >= 0.4:
            color = (0, 255, 0)      # –ó–µ–ª—ë–Ω—ã–π = –≤—ã—Å–æ–∫–∞—è
            level = "HIGH"
        elif conf_val >= 0.25:
            color = (0, 200, 255)    # –û—Ä–∞–Ω–∂–µ–≤—ã–π = —Å—Ä–µ–¥–Ω—è—è
            level = "MEDIUM"
        else:
            color = (0, 100, 255)    # –ö—Ä–∞—Å–Ω—ã–π = –Ω–∏–∑–∫–∞—è
            level = "LOW"

        # –†–∏—Å—É–µ–º —Ä–∞–º–∫—É
        cv2.rectangle(prediction_img, (x1, y1), (x2, y2), color, 3)

        # –ü–æ–¥–ø–∏—Å—å
        label = f"switch {conf_val:.2f}"
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        thickness = 2

        # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)
        cv2.rectangle(
            prediction_img,
            (x1, y1 - text_height - baseline - 8),
            (x1 + text_width + 5, y1),
            color,
            -1
        )

        # –¢–µ–∫—Å—Ç
        cv2.putText(
            prediction_img,
            label,
            (x1 + 2, y1 - baseline - 5),
            font,
            font_scale,
            (0, 0, 0),  # –ß—ë—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ü–≤–µ—Ç–Ω–æ–º —Ñ–æ–Ω–µ
            thickness
        )

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é –ø–∞–Ω–µ–ª—å –≤–≤–µ—Ä—Ö—É (PREDICTIONS)
    info_text = f"PREDICTIONS: {len(boxes)} detections (conf >= {conf_threshold:.2f})"
    cv2.rectangle(prediction_img, (0, 0), (img.shape[1], 50), (255, 255, 255), -1)
    cv2.putText(
        prediction_img,
        info_text,
        (10, 35),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.9,
        (0, 0, 0),
        2
    )

    # ===== –ü–†–ê–í–ê–Ø –ß–ê–°–¢–¨: GROUND TRUTH =====
    # –ß–∏—Ç–∞–µ–º ground truth labels
    label_path = Path("data/labels/train") / (train_image.stem + ".txt")
    gt_boxes = []

    if label_path.exists():
        with open(label_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    # YOLO format: class x_center y_center width height (normalized 0-1)
                    cls = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])

                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –ø–∏–∫—Å–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                    img_h, img_w = img.shape[:2]
                    x_center_px = x_center * img_w
                    y_center_px = y_center * img_h
                    width_px = width * img_w
                    height_px = height * img_h

                    # –í—ã—á–∏—Å–ª—è–µ–º x1, y1, x2, y2
                    x1 = int(x_center_px - width_px / 2)
                    y1 = int(y_center_px - height_px / 2)
                    x2 = int(x_center_px + width_px / 2)
                    y2 = int(y_center_px + height_px / 2)

                    gt_boxes.append((x1, y1, x2, y2, cls))

    # –†–∏—Å—É–µ–º ground truth boxes
    gt_color = (0, 255, 0)  # –ó–µ–ª—ë–Ω—ã–π –¥–ª—è GT
    for i, (x1, y1, x2, y2, cls) in enumerate(gt_boxes):
        # –†–∏—Å—É–µ–º —Ä–∞–º–∫—É
        cv2.rectangle(gt_img, (x1, y1), (x2, y2), gt_color, 3)

        # –ü–æ–¥–ø–∏—Å—å
        label = f"GT switch #{i+1}"
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        thickness = 2

        # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)
        cv2.rectangle(
            gt_img,
            (x1, y1 - text_height - baseline - 8),
            (x1 + text_width + 5, y1),
            gt_color,
            -1
        )

        # –¢–µ–∫—Å—Ç
        cv2.putText(
            gt_img,
            label,
            (x1 + 2, y1 - baseline - 5),
            font,
            font_scale,
            (0, 0, 0),
            thickness
        )

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é –ø–∞–Ω–µ–ª—å –≤–≤–µ—Ä—Ö—É (GROUND TRUTH)
    gt_info_text = f"GROUND TRUTH: {len(gt_boxes)} objects"
    cv2.rectangle(gt_img, (0, 0), (img.shape[1], 50), (255, 255, 255), -1)
    cv2.putText(
        gt_img,
        gt_info_text,
        (10, 35),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.9,
        (0, 0, 0),
        2
    )

    # ===== –°–ö–õ–ï–ò–í–ê–ï–ú –î–í–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø =====
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ (–±–µ–ª–∞—è –ø–æ–ª–æ—Å–∞)
    separator = np.ones((img.shape[0], 10, 3), dtype=np.uint8) * 255
    combined_img = np.hstack([prediction_img, separator, gt_img])

    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É results –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    results_dir = Path("results")
    results_dir.mkdir(exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)
    output_path = results_dir / "train_prediction.jpg"
    cv2.imwrite(str(output_path), combined_img)
    print(f"üíæ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {output_path}\n")
    print(f"   –õ–µ–≤–∞—è —á–∞—Å—Ç—å: Predictions ({len(boxes)} –¥–µ—Ç–µ–∫—Ü–∏–π)")
    print(f"   –ü—Ä–∞–≤–∞—è —á–∞—Å—Ç—å: Ground Truth ({len(gt_boxes)} –æ–±—ä–µ–∫—Ç–æ–≤)\n")

    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    if use_grayscale and temp_image.exists():
        temp_image.unlink()

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ confidence (–æ—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É)
    sorted_confs = sorted(conf_counts.items(), reverse=True)

    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("=" * 70)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –£–í–ï–†–ï–ù–ù–û–°–¢–ò")
    print("=" * 70)
    print(f"\n{'Confidence':<15} {'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤':>20}")
    print("-" * 70)

    total = 0
    for conf, count in sorted_confs:
        print(f"{conf:<15.2f} {count:>20} —à—Ç.")
        total += count

    print("-" * 70)
    print(f"{'–í–°–ï–ì–û:':<15} {total:>20} —à—Ç.")

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 70)
    print("üìà –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 70)
    print(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è confidence: {min(confidences):.3f}")
    print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è confidence: {max(confidences):.3f}")
    print(f"–°—Ä–µ–¥–Ω—è—è confidence:     {sum(confidences)/len(confidences):.3f}")

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º
    print("\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º:")
    ranges = [
        (0.9, 1.0, "0.9-1.0 (–æ—Ç–ª–∏—á–Ω–æ)"),
        (0.7, 0.9, "0.7-0.9 (—Ö–æ—Ä–æ—à–æ)"),
        (0.5, 0.7, "0.5-0.7 (—Å—Ä–µ–¥–Ω–µ)"),
        (0.3, 0.5, "0.3-0.5 (—Å–ª–∞–±–æ)"),
        (0.0, 0.3, "0.0-0.3 (–æ—á–µ–Ω—å —Å–ª–∞–±–æ)"),
    ]

    for min_conf, max_conf, label in ranges:
        count = sum(1 for c in confidences if min_conf <= c < max_conf)
        if count > 0:
            percentage = (count / total) * 100
            bar = "‚ñà" * int(percentage / 2)
            print(f"  {label:<25} {count:>3} —à—Ç. ({percentage:>5.1f}%) {bar}")

    print("\n" + "=" * 70 + "\n")

def main():
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config_file = sys.argv[1] if len(sys.argv) > 1 else "train_config.yaml"

    print("\n" + "=" * 70)
    print("üéØ –ë–´–°–¢–†–´–ô WORKFLOW: –û–ë–£–ß–ï–ù–ò–ï ‚Üí –¢–ï–°–¢ ‚Üí –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 70)
    print(f"üìÑ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {config_file}\n")

    config = load_config(config_file)

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    # defaults = {
    #     'experiment_name': 'quick_test',
    #     'model': 'yolo11n.pt',
    #     'epochs': 150,
    #     'imgsz': 1280,
    #     'batch': 2,
    #     'optimizer': 'auto',
    #     'lr0': 0.002,
    #     'lrf': 0.01,
    #     'momentum': 0.937,
    #     'weight_decay': 0.0005,
    #     'mosaic': 0.0,
    #     'degrees': 0.0,
    #     'translate': 0.0,
    #     'scale': 0.0,
    #     'fliplr': 0.0,
    #     'flipud': 0.0,
    #     'shear': 0.0,
    #     'hsv_h': 0.015,
    #     'hsv_s': 0.5,
    #     'hsv_v': 0.4,
    #     'dropout': 0.0,
    #     'mixup': 0.0,
    #     'copy_paste': 0.0,
    #     'box': 7.5,
    #     'cls': 0.5,
    #     'dfl': 1.5,
    #     'patience': 50,
    #     'close_mosaic': 10,
    #     'warmup_epochs': 3.0,
    #     'cos_lr': False,
    #     'conf_threshold': 0.1,
    #     'iou_threshold': 0.45,
    #     'grayscale': False,
    # }

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –¥–µ—Ñ–æ–ª—Ç–∞–º–∏
    # for key, value in defaults.items():
    #     config.setdefault(key, value)

    # 1. –û–±—É—á–µ–Ω–∏–µ
    model_path = train_model(config)

    # 2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    conf_threshold = config.get('conf_threshold', 0.1)
    use_grayscale = config.get('grayscale', False)
    test_on_train_image(model_path, conf_threshold, use_grayscale)

    print("‚úÖ –ì–æ—Ç–æ–≤–æ! –ò–∑–º–µ–Ω–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ train_config.yaml –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–æ–≤–∞\n")

if __name__ == "__main__":
    main()
