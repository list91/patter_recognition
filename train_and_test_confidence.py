#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏ –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
—Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ confidence.
"""

import yaml
import sys
from pathlib import Path
from ultralytics import YOLO
from collections import Counter
import cv2
import numpy as np
import shutil
import random

def load_config(config_path="train_config.yaml"):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ YAML —Ñ–∞–π–ª–∞."""
    if not Path(config_path).exists():
        print(f"‚ö†Ô∏è  –ö–æ–Ω—Ñ–∏–≥ {config_path} –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        return {}

    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config

def convert_to_grayscale_dataset(source_dir, target_dir):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ grayscale –∏ –∫–æ–ø–∏—Ä—É–µ—Ç –≤ —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é."""
    source_path = Path(source_dir)
    target_path = Path(target_dir)

    # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    target_path.mkdir(parents=True, exist_ok=True)

    print(f"üé® –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —á–µ—Ä–Ω–æ-–±–µ–ª—ã–µ...")
    print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {source_path}")
    print(f"   –¶–µ–ª—å: {target_path}")

    converted_count = 0
    for img_file in source_path.glob("*.jpg"):
        # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = cv2.imread(str(img_file))
        if img is None:
            continue

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ 3-–∫–∞–Ω–∞–ª—å–Ω–æ–µ (–¥—É–±–ª–∏—Ä—É–µ–º –∫–∞–Ω–∞–ª)
        # –≠—Ç–æ –Ω—É–∂–Ω–æ –ø–æ—Ç–æ–º—É —á—Ç–æ YOLO –æ–∂–∏–¥–∞–µ—Ç 3-–∫–∞–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        gray_3ch = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        target_file = target_path / img_file.name
        cv2.imwrite(str(target_file), gray_3ch)
        converted_count += 1

    print(f"   ‚úì –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {converted_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n")
    return target_path

def prepare_grayscale_dataset():
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —á–µ—Ä–Ω–æ-–±–µ–ª—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."""
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º train –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    train_source = Path("data/images/train")
    train_target = Path("data/images/train_grayscale")
    convert_to_grayscale_dataset(train_source, train_target)

    # –ö–æ–ø–∏—Ä—É–µ–º labels
    labels_source = Path("data/labels/train")
    labels_target = Path("data/labels/train_grayscale")

    labels_target.mkdir(parents=True, exist_ok=True)

    for label_file in labels_source.glob("*.txt"):
        shutil.copy2(label_file, labels_target / label_file.name)

    print(f"   ‚úì –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã –º–µ—Ç–∫–∏ –≤ {labels_target}\n")

    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π data.yaml –¥–ª—è grayscale
    data_yaml_content = """path: ./data
train: images/train_grayscale
val: images/train_grayscale
nc: 1
names: ['switch']
"""

    with open("data_grayscale.yaml", 'w') as f:
        f.write(data_yaml_content)

    print(f"   ‚úì –°–æ–∑–¥–∞–Ω data_grayscale.yaml\n")

    return "data_grayscale.yaml"

def train_model(config):
    """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
    print("=" * 70)
    print("üöÄ –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("=" * 70)
    print(f"\nüìã –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {config.get('experiment_name', 'default')}")
    print(f"üì¶ –ú–æ–¥–µ–ª—å: {config.get('model', 'yolo11n.pt')}")
    print(f"‚è±Ô∏è  –≠–ø–æ—Ö–∏: {config.get('epochs', 150)}")
    print(f"üìê –†–∞–∑–º–µ—Ä: {config.get('imgsz', 1280)}")
    print(f"üéØ Confidence threshold: {config.get('conf_threshold', 0.1)}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–∏–º grayscale
    use_grayscale = config.get('grayscale', False)
    print(f"üé® –†–µ–∂–∏–º: {'–ß–µ—Ä–Ω–æ-–±–µ–ª—ã–π (grayscale)' if use_grayscale else '–¶–≤–µ—Ç–Ω–æ–π (RGB)'}\n")

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    if use_grayscale:
        data_yaml = prepare_grayscale_dataset()
    else:
        data_yaml = "data.yaml"

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = YOLO(config.get('model', 'yolo11n.pt'))

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
    print("‚è≥ –û–±—É—á–µ–Ω–∏–µ –Ω–∞—á–∞–ª–æ—Å—å...\n")
    results = model.train(
        data=data_yaml,

        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        epochs=config.get('epochs', 150),
        imgsz=config.get('imgsz', 1280),
        batch=config.get('batch', 2),

        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
        optimizer=config.get('optimizer', 'auto'),
        lr0=config.get('lr0', 0.002),
        lrf=config.get('lrf', 0.01),
        momentum=config.get('momentum', 0.937),
        weight_decay=config.get('weight_decay', 0.0005),

        # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        mosaic=config.get('mosaic', 0.0),
        degrees=config.get('degrees', 0.0),
        translate=config.get('translate', 0.0),
        scale=config.get('scale', 0.0),
        fliplr=config.get('fliplr', 0.0),
        flipud=config.get('flipud', 0.0),
        shear=config.get('shear', 0.0),
        hsv_h=config.get('hsv_h', 0.015),
        hsv_s=config.get('hsv_s', 0.5),
        hsv_v=config.get('hsv_v', 0.4),

        # –ü–æ—Ç–µ—Ä–∏
        box=config.get('box', 7.5),
        cls=config.get('cls', 0.5),
        dfl=config.get('dfl', 1.5),

        # –î—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        patience=config.get('patience', 50),
        device="cpu",
        workers=2,
        project="runs/detect",
        name="quick_train",
        exist_ok=True,  # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º
        verbose=False,  # –ú–µ–Ω—å—à–µ –≤—ã–≤–æ–¥–∞
        plots=True,
    )

    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
    best_model_path = Path(model.trainer.save_dir) / "weights" / "best.pt"

    print("\n" + "=" * 70)
    print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 70)
    print(f"üìÅ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {best_model_path}\n")

    return best_model_path

def test_on_train_image(model_path, conf_threshold=0.1, use_grayscale=False):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."""
    print("=" * 70)
    print("üîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –¢–†–ï–ù–ò–†–û–í–û–ß–ù–û–ú –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ò")
    print("=" * 70)

    train_image = Path("data/images/train/train_00.jpg")

    if not train_image.exists():
        print(f"‚ùå –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {train_image}")
        return

    print(f"\nüì∑ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {train_image}")
    print(f"üéØ –ü–æ—Ä–æ–≥ confidence: {conf_threshold}")
    print(f"üé® –†–µ–∂–∏–º: {'–ß–µ—Ä–Ω–æ-–±–µ–ª—ã–π (grayscale)' if use_grayscale else '–¶–≤–µ—Ç–Ω–æ–π (RGB)'}\n")

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    if use_grayscale:
        # –ß–∏—Ç–∞–µ–º –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale
        img = cv2.imread(str(train_image))
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        gray_3ch = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ
        temp_image = Path("data/images/train/train_00_grayscale_temp.jpg")
        cv2.imwrite(str(temp_image), gray_3ch)
        test_image = temp_image
    else:
        test_image = train_image

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = YOLO(model_path)

    # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    results = model.predict(
        source=str(test_image),
        imgsz=1280,
        conf=conf_threshold,
        iou=0.45,
        save=False,
        verbose=False,
    )

    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    result = results[0]
    boxes = result.boxes

    if len(boxes) == 0:
        print("‚ùå –û–±—ä–µ–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
        print("   - –°–Ω–∏–∑–∏—Ç—å conf_threshold")
        print("   - –£–≤–µ–ª–∏—á–∏—Ç—å epochs")
        print("   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à—É—é –º–æ–¥–µ–ª—å\n")

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        if use_grayscale and temp_image.exists():
            temp_image.unlink()
        return

    confidences = boxes.conf.cpu().numpy()

    # –ß–∏—Ç–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
    if use_grayscale:
        img = cv2.imread(str(test_image))
    else:
        img = cv2.imread(str(train_image))

    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
    annotated_img = img.copy()

    # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ —Å–æ—Ç—ã—Ö –∏ —Å—á–∏—Ç–∞–µ–º
    rounded_confs = [round(float(c), 2) for c in confidences]
    conf_counts = Counter(rounded_confs)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Ü–≤–µ—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ confidence
    unique_confs = sorted(conf_counts.keys(), reverse=True)
    color_map = {}

    for conf_val in unique_confs:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —è—Ä–∫–∏–π —Ü–≤–µ—Ç (BGR —Ñ–æ—Ä–º–∞—Ç –¥–ª—è OpenCV)
        color = (
            random.randint(50, 255),
            random.randint(50, 255),
            random.randint(50, 255)
        )
        color_map[conf_val] = color

    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã boxes
    boxes_xyxy = boxes.xyxy.cpu().numpy()

    # –†–∏—Å—É–µ–º –∫–∞–∂–¥—ã–π bbox —Å–≤–æ–∏–º —Ü–≤–µ—Ç–æ–º
    for i, (box, conf) in enumerate(zip(boxes_xyxy, confidences)):
        conf_rounded = round(float(conf), 2)
        color = color_map[conf_rounded]

        x1, y1, x2, y2 = map(int, box)

        # –†–∏—Å—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
        cv2.rectangle(annotated_img, (x1, y1), (x2, y2), color, 3)

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
        label = f"switch {conf_rounded:.2f}"

        # –†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        thickness = 2
        (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)

        # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        cv2.rectangle(
            annotated_img,
            (x1, y1 - text_height - baseline - 5),
            (x1 + text_width, y1),
            color,
            -1
        )

        # –¢–µ–∫—Å—Ç
        cv2.putText(
            annotated_img,
            label,
            (x1, y1 - baseline - 5),
            font,
            font_scale,
            (255, 255, 255),
            thickness
        )

    # –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–µ–Ω–¥—É
    legend_height = 40 + len(unique_confs) * 35
    legend_width = 250
    legend_x = annotated_img.shape[1] - legend_width - 20
    legend_y = 20

    # –ü–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω –¥–ª—è –ª–µ–≥–µ–Ω–¥—ã
    overlay = annotated_img.copy()
    cv2.rectangle(
        overlay,
        (legend_x, legend_y),
        (legend_x + legend_width, legend_y + legend_height),
        (255, 255, 255),
        -1
    )
    cv2.addWeighted(overlay, 0.7, annotated_img, 0.3, 0, annotated_img)

    # –†–∞–º–∫–∞ –ª–µ–≥–µ–Ω–¥—ã
    cv2.rectangle(
        annotated_img,
        (legend_x, legend_y),
        (legend_x + legend_width, legend_y + legend_height),
        (0, 0, 0),
        2
    )

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ª–µ–≥–µ–Ω–¥—ã
    cv2.putText(
        annotated_img,
        "Confidence Legend:",
        (legend_x + 10, legend_y + 25),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.6,
        (0, 0, 0),
        2
    )

    # –≠–ª–µ–º–µ–Ω—Ç—ã –ª–µ–≥–µ–Ω–¥—ã
    for idx, conf_val in enumerate(unique_confs):
        y_pos = legend_y + 50 + idx * 35
        color = color_map[conf_val]
        count = conf_counts[conf_val]

        # –¶–≤–µ—Ç–Ω–æ–π –∫–≤–∞–¥—Ä–∞—Ç
        cv2.rectangle(
            annotated_img,
            (legend_x + 10, y_pos - 15),
            (legend_x + 30, y_pos + 5),
            color,
            -1
        )
        cv2.rectangle(
            annotated_img,
            (legend_x + 10, y_pos - 15),
            (legend_x + 30, y_pos + 5),
            (0, 0, 0),
            1
        )

        # –¢–µ–∫—Å—Ç
        text = f"{conf_val:.2f} ({count} —à—Ç.)"
        cv2.putText(
            annotated_img,
            text,
            (legend_x + 40, y_pos),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (0, 0, 0),
            1
        )

    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É results –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    results_dir = Path("results")
    results_dir.mkdir(exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)
    output_path = results_dir / "train_prediction.jpg"
    cv2.imwrite(str(output_path), annotated_img)
    print(f"üíæ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {output_path}\n")

    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    if use_grayscale and temp_image.exists():
        temp_image.unlink()

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ confidence (–æ—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É)
    sorted_confs = sorted(conf_counts.items(), reverse=True)

    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("=" * 70)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –£–í–ï–†–ï–ù–ù–û–°–¢–ò")
    print("=" * 70)
    print(f"\n{'Confidence':<15} {'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤':>20}")
    print("-" * 70)

    total = 0
    for conf, count in sorted_confs:
        print(f"{conf:<15.2f} {count:>20} —à—Ç.")
        total += count

    print("-" * 70)
    print(f"{'–í–°–ï–ì–û:':<15} {total:>20} —à—Ç.")

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 70)
    print("üìà –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 70)
    print(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è confidence: {min(confidences):.3f}")
    print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è confidence: {max(confidences):.3f}")
    print(f"–°—Ä–µ–¥–Ω—è—è confidence:     {sum(confidences)/len(confidences):.3f}")

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º
    print("\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º:")
    ranges = [
        (0.9, 1.0, "0.9-1.0 (–æ—Ç–ª–∏—á–Ω–æ)"),
        (0.7, 0.9, "0.7-0.9 (—Ö–æ—Ä–æ—à–æ)"),
        (0.5, 0.7, "0.5-0.7 (—Å—Ä–µ–¥–Ω–µ)"),
        (0.3, 0.5, "0.3-0.5 (—Å–ª–∞–±–æ)"),
        (0.0, 0.3, "0.0-0.3 (–æ—á–µ–Ω—å —Å–ª–∞–±–æ)"),
    ]

    for min_conf, max_conf, label in ranges:
        count = sum(1 for c in confidences if min_conf <= c < max_conf)
        if count > 0:
            percentage = (count / total) * 100
            bar = "‚ñà" * int(percentage / 2)
            print(f"  {label:<25} {count:>3} —à—Ç. ({percentage:>5.1f}%) {bar}")

    print("\n" + "=" * 70 + "\n")

def main():
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config_file = sys.argv[1] if len(sys.argv) > 1 else "train_config.yaml"

    print("\n" + "=" * 70)
    print("üéØ –ë–´–°–¢–†–´–ô WORKFLOW: –û–ë–£–ß–ï–ù–ò–ï ‚Üí –¢–ï–°–¢ ‚Üí –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 70)
    print(f"üìÑ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {config_file}\n")

    config = load_config(config_file)

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    # defaults = {
    #     'experiment_name': 'quick_test',
    #     'model': 'yolo11n.pt',
    #     'epochs': 150,
    #     'imgsz': 1280,
    #     'batch': 2,
    #     'optimizer': 'auto',
    #     'lr0': 0.002,
    #     'lrf': 0.01,
    #     'momentum': 0.937,
    #     'weight_decay': 0.0005,
    #     'mosaic': 0.0,
    #     'degrees': 0.0,
    #     'translate': 0.0,
    #     'scale': 0.0,
    #     'fliplr': 0.0,
    #     'flipud': 0.0,
    #     'shear': 0.0,
    #     'hsv_h': 0.015,
    #     'hsv_s': 0.5,
    #     'hsv_v': 0.4,
    #     'dropout': 0.0,
    #     'mixup': 0.0,
    #     'copy_paste': 0.0,
    #     'box': 7.5,
    #     'cls': 0.5,
    #     'dfl': 1.5,
    #     'patience': 50,
    #     'close_mosaic': 10,
    #     'warmup_epochs': 3.0,
    #     'cos_lr': False,
    #     'conf_threshold': 0.1,
    #     'iou_threshold': 0.45,
    #     'grayscale': False,
    # }

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –¥–µ—Ñ–æ–ª—Ç–∞–º–∏
    # for key, value in defaults.items():
    #     config.setdefault(key, value)

    # 1. –û–±—É—á–µ–Ω–∏–µ
    model_path = train_model(config)

    # 2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    conf_threshold = config.get('conf_threshold', 0.1)
    use_grayscale = config.get('grayscale', False)
    test_on_train_image(model_path, conf_threshold, use_grayscale)

    print("‚úÖ –ì–æ—Ç–æ–≤–æ! –ò–∑–º–µ–Ω–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ train_config.yaml –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–æ–≤–∞\n")

if __name__ == "__main__":
    main()
