#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º –ø–æ—Ä–æ–≥–æ–º confidence.
–°–æ–∑–¥–∞—ë—Ç side-by-side —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ: predictions vs ground truth.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python predict_and_visualize.py --model runs/detect/quick_train/weights/best.pt --image data/images/train/train_00.jpg --conf 0.25
    python predict_and_visualize.py --model runs/detect/quick_train/weights/best.pt --image data/images/train/train_00.jpg --conf 0.35 --output custom_result.jpg
"""

import argparse
import sys
from pathlib import Path
from ultralytics import YOLO
from collections import Counter
import cv2
import numpy as np


def predict_and_visualize(model_path, image_path, conf_threshold=0.25, output_path=None):
    """
    –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏ —Å–æ–∑–¥–∞—ë—Ç side-by-side –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é.

    Args:
        model_path: –ø—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (.pt —Ñ–∞–π–ª)
        image_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        conf_threshold: –ø–æ—Ä–æ–≥ confidence (0.0-1.0)
        output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ø—É—Ç–∏ –≤ Path –æ–±—ä–µ–∫—Ç—ã
    model_path = Path(model_path)
    image_path = Path(image_path)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
    if not model_path.exists():
        print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
        return

    if not image_path.exists():
        print(f"‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {image_path}")
        return

    print("=" * 70)
    print("üîç –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô")
    print("=" * 70)
    print(f"\nüì¶ –ú–æ–¥–µ–ª—å: {model_path}")
    print(f"üì∑ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
    print(f"üéØ –ü–æ—Ä–æ–≥ confidence: {conf_threshold}")
    print(f"üìê –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_path.stat().st_size / 1024:.1f} KB\n")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    print("‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    model = YOLO(str(model_path))
    print("‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n")

    # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    print("‚è≥ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")
    results = model.predict(
        source=str(image_path),
        imgsz=1280,
        conf=conf_threshold,
        iou=0.45,
        save=False,
        verbose=False,
    )

    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    result = results[0]
    boxes = result.boxes

    print(f"‚úì –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: –Ω–∞–π–¥–µ–Ω–æ {len(boxes)} –æ–±—ä–µ–∫—Ç–æ–≤\n")

    if len(boxes) == 0:
        print("‚ùå –û–±—ä–µ–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:")
        print(f"   - –°–Ω–∏–∑–∏—Ç—å conf_threshold (—Ç–µ–∫—É—â–∏–π: {conf_threshold})")
        print("   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å")
        print("   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n")
        return

    # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    img = cv2.imread(str(image_path))
    if img is None:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
        return

    # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏–∏ –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
    prediction_img = img.copy()
    gt_img = img.copy()

    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–µ—Ç–µ–∫—Ü–∏—è—Ö
    confidences = boxes.conf.cpu().numpy()
    boxes_xyxy = boxes.xyxy.cpu().numpy()

    # ===== –õ–ï–í–ê–Ø –ß–ê–°–¢–¨: PREDICTIONS =====
    for i, (box, conf) in enumerate(zip(boxes_xyxy, confidences)):
        conf_val = float(conf)
        x1, y1, x2, y2 = map(int, box)

        # –¶–≤–µ—Ç –ø–æ —É—Ä–æ–≤–Ω—é confidence
        if conf_val >= 0.7:
            color = (0, 255, 0)      # –ó–µ–ª—ë–Ω—ã–π = –æ—Ç–ª–∏—á–Ω–æ
        elif conf_val >= 0.5:
            color = (0, 200, 255)    # –û—Ä–∞–Ω–∂–µ–≤—ã–π = —Ö–æ—Ä–æ—à–æ
        elif conf_val >= 0.3:
            color = (0, 150, 255)    # –°–≤–µ—Ç–ª–æ-–æ—Ä–∞–Ω–∂–µ–≤—ã–π = —Å—Ä–µ–¥–Ω–µ
        else:
            color = (0, 100, 255)    # –ö—Ä–∞—Å–Ω—ã–π = —Å–ª–∞–±–æ

        # –†–∏—Å—É–µ–º —Ä–∞–º–∫—É
        cv2.rectangle(prediction_img, (x1, y1), (x2, y2), color, 3)

        # –ü–æ–¥–ø–∏—Å—å
        label = f"switch {conf_val:.2f}"
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        thickness = 2

        # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)
        cv2.rectangle(
            prediction_img,
            (x1, y1 - text_height - baseline - 8),
            (x1 + text_width + 5, y1),
            color,
            -1
        )

        # –¢–µ–∫—Å—Ç
        cv2.putText(
            prediction_img,
            label,
            (x1 + 2, y1 - baseline - 5),
            font,
            font_scale,
            (0, 0, 0),  # –ß—ë—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ü–≤–µ—Ç–Ω–æ–º —Ñ–æ–Ω–µ
            thickness
        )

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é –ø–∞–Ω–µ–ª—å –≤–≤–µ—Ä—Ö—É (PREDICTIONS)
    info_text = f"PREDICTIONS: {len(boxes)} detections (conf >= {conf_threshold:.2f})"
    cv2.rectangle(prediction_img, (0, 0), (img.shape[1], 50), (255, 255, 255), -1)
    cv2.putText(
        prediction_img,
        info_text,
        (10, 35),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.9,
        (0, 0, 0),
        2
    )

    # ===== –ü–†–ê–í–ê–Ø –ß–ê–°–¢–¨: GROUND TRUTH =====
    # –ò—â–µ–º —Ñ–∞–π–ª —Ä–∞–∑–º–µ—Ç–∫–∏ (–¥–≤–∞ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—É—Ç–∏)
    # –í–∞—Ä–∏–∞–Ω—Ç 1: data/labels/train/image.txt (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ YOLO)
    label_path = Path("data/labels") / image_path.parent.name / (image_path.stem + ".txt")

    # –í–∞—Ä–∏–∞–Ω—Ç 2: –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—â–µ–º —Ä—è–¥–æ–º —Å images
    if not label_path.exists():
        label_path = image_path.parent.parent / "labels" / image_path.parent.name / (image_path.stem + ".txt")

    gt_boxes = []

    if label_path.exists():
        with open(label_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    # YOLO format: class x_center y_center width height (normalized 0-1)
                    cls = int(parts[0])
                    x_center = float(parts[1])
                    y_center = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])

                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –ø–∏–∫—Å–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                    img_h, img_w = img.shape[:2]
                    x_center_px = x_center * img_w
                    y_center_px = y_center * img_h
                    width_px = width * img_w
                    height_px = height * img_h

                    # –í—ã—á–∏—Å–ª—è–µ–º x1, y1, x2, y2
                    x1 = int(x_center_px - width_px / 2)
                    y1 = int(y_center_px - height_px / 2)
                    x2 = int(x_center_px + width_px / 2)
                    y2 = int(y_center_px + height_px / 2)

                    gt_boxes.append((x1, y1, x2, y2, cls))

        # –†–∏—Å—É–µ–º ground truth boxes
        gt_color = (0, 255, 0)  # –ó–µ–ª—ë–Ω—ã–π –¥–ª—è GT
        for i, (x1, y1, x2, y2, cls) in enumerate(gt_boxes):
            # –†–∏—Å—É–µ–º —Ä–∞–º–∫—É
            cv2.rectangle(gt_img, (x1, y1), (x2, y2), gt_color, 3)

            # –ü–æ–¥–ø–∏—Å—å
            label = f"GT switch #{i+1}"
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.7
            thickness = 2

            # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)
            cv2.rectangle(
                gt_img,
                (x1, y1 - text_height - baseline - 8),
                (x1 + text_width + 5, y1),
                gt_color,
                -1
            )

            # –¢–µ–∫—Å—Ç
            cv2.putText(
                gt_img,
                label,
                (x1 + 2, y1 - baseline - 5),
                font,
                font_scale,
                (0, 0, 0),
                thickness
            )

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—É—é –ø–∞–Ω–µ–ª—å –≤–≤–µ—Ä—Ö—É (GROUND TRUTH)
        gt_info_text = f"GROUND TRUTH: {len(gt_boxes)} objects"
        cv2.rectangle(gt_img, (0, 0), (img.shape[1], 50), (255, 255, 255), -1)
        cv2.putText(
            gt_img,
            gt_info_text,
            (10, 35),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.9,
            (0, 0, 0),
            2
        )
    else:
        # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ç–∫–∏ –Ω–µ—Ç, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ predictions
        print(f"‚ö†Ô∏è  Ground truth —Ä–∞–∑–º–µ—Ç–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {label_path}")
        print("   –ë—É–¥–µ—Ç –ø–æ–∫–∞–∑–∞–Ω–æ —Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏\n")
        gt_img = None

    # ===== –°–ö–õ–ï–ò–í–ê–ï–ú –î–í–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø =====
    if gt_img is not None:
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ (–±–µ–ª–∞—è –ø–æ–ª–æ—Å–∞)
        separator = np.ones((img.shape[0], 10, 3), dtype=np.uint8) * 255
        combined_img = np.hstack([prediction_img, separator, gt_img])
    else:
        # –¢–æ–ª—å–∫–æ predictions
        combined_img = prediction_img

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    if output_path is None:
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ results/
        results_dir = Path("results")
        results_dir.mkdir(exist_ok=True)
        output_path = results_dir / f"prediction_{image_path.stem}_conf{conf_threshold:.2f}.jpg"
    else:
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    cv2.imwrite(str(output_path), combined_img)

    print("=" * 70)
    print("‚úÖ –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
    print("=" * 70)
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")
    print(f"   –†–∞–∑–º–µ—Ä: {output_path.stat().st_size / 1024:.1f} KB")

    if gt_img is not None:
        print(f"\n   –õ–µ–≤–∞—è —á–∞—Å—Ç—å: Predictions ({len(boxes)} –¥–µ—Ç–µ–∫—Ü–∏–π)")
        print(f"   –ü—Ä–∞–≤–∞—è —á–∞—Å—Ç—å: Ground Truth ({len(gt_boxes)} –æ–±—ä–µ–∫—Ç–æ–≤)")
    else:
        print(f"\n   Predictions: {len(boxes)} –¥–µ—Ç–µ–∫—Ü–∏–π")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ confidence
    print("\n" + "=" * 70)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –£–í–ï–†–ï–ù–ù–û–°–¢–ò")
    print("=" * 70)
    print(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è confidence: {min(confidences):.3f}")
    print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è confidence: {max(confidences):.3f}")
    print(f"–°—Ä–µ–¥–Ω—è—è confidence:     {sum(confidences)/len(confidences):.3f}")

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º
    print("\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º:")
    ranges = [
        (0.9, 1.0, "0.9-1.0 (–æ—Ç–ª–∏—á–Ω–æ)"),
        (0.7, 0.9, "0.7-0.9 (—Ö–æ—Ä–æ—à–æ)"),
        (0.5, 0.7, "0.5-0.7 (—Å—Ä–µ–¥–Ω–µ)"),
        (0.3, 0.5, "0.3-0.5 (—Å–ª–∞–±–æ)"),
        (0.0, 0.3, "0.0-0.3 (–æ—á–µ–Ω—å —Å–ª–∞–±–æ)"),
    ]

    for min_conf, max_conf, label in ranges:
        count = sum(1 for c in confidences if min_conf <= c < max_conf)
        if count > 0:
            percentage = (count / len(confidences)) * 100
            bar = "‚ñà" * int(percentage / 2)
            print(f"  {label:<25} {count:>3} —à—Ç. ({percentage:>5.1f}%) {bar}")

    print("\n" + "=" * 70 + "\n")


def main():
    parser = argparse.ArgumentParser(
        description="–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ–±—É—á–µ–Ω–Ω–æ–π YOLO –º–æ–¥–µ–ª–∏ —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º –ø–æ—Ä–æ–≥–æ–º confidence",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ (conf=0.25 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
  python predict_and_visualize.py --model runs/detect/quick_train/weights/best.pt --image data/images/train/train_00.jpg

  # –° –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º –ø–æ—Ä–æ–≥–æ–º confidence
  python predict_and_visualize.py --model runs/detect/quick_train/weights/best.pt --image data/images/train/train_00.jpg --conf 0.35

  # –° —É–∫–∞–∑–∞–Ω–∏–µ–º –ø—É—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
  python predict_and_visualize.py --model runs/detect/quick_train/weights/best.pt --image data/images/train/train_00.jpg --conf 0.40 --output my_result.jpg

  # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ test –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
  python predict_and_visualize.py --model runs/detect/quick_train/weights/best.pt --image data/images/test/test_01.jpg --conf 0.25
        """
    )

    parser.add_argument(
        "--model", "-m",
        type=str,
        default="runs/detect/quick_train/weights/best.pt",
        help="–ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (.pt —Ñ–∞–π–ª). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: runs/detect/quick_train/weights/best.pt"
    )

    parser.add_argument(
        "--image", "-i",
        type=str,
        required=True,
        help="–ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä)"
    )

    parser.add_argument(
        "--conf", "-c",
        type=float,
        default=0.25,
        help="–ü–æ—Ä–æ–≥ confidence (0.0-1.0). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.25"
    )

    parser.add_argument(
        "--output", "-o",
        type=str,
        default=None,
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: results/prediction_<–∏–º—è>_conf<–ø–æ—Ä–æ–≥>.jpg"
    )

    args = parser.parse_args()

    # –í–∞–ª–∏–¥–∞—Ü–∏—è confidence threshold
    if not 0.0 <= args.conf <= 1.0:
        print("‚ùå –û—à–∏–±–∫–∞: confidence threshold –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 0.0-1.0")
        sys.exit(1)

    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    predict_and_visualize(
        model_path=args.model,
        image_path=args.image,
        conf_threshold=args.conf,
        output_path=args.output
    )


if __name__ == "__main__":
    main()
